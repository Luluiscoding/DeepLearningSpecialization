{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Neural Network\n",
    "\n",
    "## Binary Classification\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "### Basics for logistic regression\n",
    "\n",
    "### logestic regression Cost Function\n",
    "\n",
    "\n",
    "\n",
    "### logestic regression gradient descent\n",
    "\n",
    "<img src=\"images/gd with 1 example.png\" width=\"600\">\n",
    "\n",
    "<img src=\"images/gd with m examples.png\" width=\"600\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "## What is vectorization?  \n",
    "\n",
    "In Deep Learning, vectorization refers to the process of converting an operation that acts on scalar values to an equivalent operation that acts on vectors or matrices of those values. Vectorization is a key technique for optimizing the performance of deep learning models, as it allows large amounts of data to be processed more efficiently by taking advantage of parallel computing architectures. \n",
    "\n",
    "Vectorization can help us get rid of explicit for loops in our codes and save time in the deep learning area."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Logistic Regression\n",
    "\n",
    "In logistic regression, we compute $Z = W^{T}*X+b$, $W$ and $X$ are both column vectors. Here is the comparison between \"for loop\" method and \"vectorizaiton\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250322.06153138122\n",
      "vectorization version:458.3883285522461ms\n",
      "250322.06153138046\n",
      "for loop version:568.7224864959717ms\n",
      "the for loop version spent 1.2 times the time of the vectorization version.\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(1000000) \n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "tic=time.time()\n",
    "c=np.dot(a,b)\n",
    "toc=time.time()\n",
    "print(c)\n",
    "x=str(1000*(toc-tic))\n",
    "print(\"vectorization version:\" + x +\"ms\")\n",
    "\n",
    "c=0\n",
    "tic=time.time()\n",
    "for i in range(1000000):\n",
    "  c+=a[i]*b[i]\n",
    "toc=time.time()\n",
    "xx=str(1000*(toc-tic))\n",
    "\n",
    "print(c)\n",
    "print(\"for loop version:\" + xx +\"ms\")\n",
    "print(\"the for loop version spent \" + str(round(float(xx)/float(x),1)) + \" times the time of the vectorization version.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecorizing Logistic Regression\n",
    "\n",
    "Using $n_x=4,m=3$ in our example.  \n",
    "Recall that $n_x$ is the number of input feature vector (input size) and $m$ is the number of examples in the dataset:\n",
    "\n",
    "$X=\\left[\\begin{array}{lll}x^{(1)} & x^{(2)} & x^{(3)} \\\\ x^{(1)} & x^{(2)} & x^{(3)} \\\\ x^{(1)} & x^{(2)} & x^{(3)}\\\\ x^{(1)} & x^{(2)} & x^{(3)}\\end{array}\\right] \\quad w^{T}=\\left[w_1, w_2, w_3, w_4\\right]$  \n",
    "\n",
    "X.shape=(4,3); w.shape=(1,4)  \n",
    "$\\begin{aligned} Z=\\left[z^{(1)}, z^{(2)}, z^{(3)}\\right] & =w^T X+b \\\\ & = \\left[\\begin{array}{ll}w_1, w_2, w_3, w_4\\end{array}\\right]\\left[\\begin{array}{lll}x^{(1)} & x^{(2)} & x^{(3)} \\\\ x^{(1)} & x^{(2)} & x^{(3)} \\\\ x^{(1)} & x^{(2)} & x^{(3)}\\\\ x^{(1)} & x^{(2)} & x^{(3)}\\end{array}\\right]+[b,b,b]\\\\\n",
    "& =[w^T x^{(1)}+b,w^T x^{(2)}+b,w^T x^{(3)}+b]\n",
    "\\end{aligned}$  \n",
    "In Python, we use the command Z=np.dot(wT,X)+b to compute.  \n",
    "\n",
    "Here, b is a real number, when adding this vector to this real number, Python automatically takes this real number b and expands it out to a 1*m matrix, which is called **\"broadcasting\"**.  \n",
    "Next, $A=[a^{(1)},a^{(2)},a^{(3)}]=[\\sigma(z^{(1)}),\\sigma(z^{(2)}),\\sigma(z^{(3)})]$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Logistic Regression's Gradient Output\n",
    "\n",
    "In the previous notes, we have already derived that $dz=a-y$. So, consider the vectorization, we get:  \n",
    "$dz^{(1)}=a^{(1)}-y^{(1)},dz^{(2)}=a^{(2)}-y^{(2)},dz^{(3)}=a^{(3)}-y^{(3)}$  \n",
    "$dZ,A,Y$ are respective 1*m matrix.  \n",
    "$dZ=A-Y=[a^{(1)}-y^{(1)},a^{(2)}-y^{(2)},a^{(3)}-y^{(3)}]$  \n",
    "In Python  \n",
    "- the calculation logistic for $w$ is:  \n",
    "$\\begin{array}{l}d w=0 \\\\ dw +=x^{(1)} d z^{(1)} \\\\ d w+=x^{(2)} d z^{(2)} \\\\ d w+=x^{(3)} d z^{(3)} \\\\ \\vdots \\\\ d w=d w / m\\end{array}$  \n",
    "- the calculation logistic for $b$ is:  \n",
    "$\\begin{array}{l}d b=0 \\\\ d b+=d z^{(1)} \\\\ d b+=d z^{(2)} \\\\ d b+=d z^{(3)} \\\\ \\vdots \\\\ d b=d b / m\\end{array}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, the above logistics are concluded as:  \n",
    "\n",
    "$ \\text{For} \\  i=1 \\  to \\  m : $  \n",
    "$ \\qquad z^{(i)}=w^{T} x^{(i)}+b \\\\ \\qquad a^{(i)}=\\sigma \\left(z^{(i)}\\right) \\\\ \\qquad J+=-\\left[y^{(i)} \\log a^{(i)}+\\left(1-y^{(i)}\\right) \\log \\left(1-a^{(i)}\\right)\\right] \\\\ \\qquad d z^{(i)}=a^{(i)}-y^{(i)} \\\\ \\qquad d w_1+= x_1^{(i)} d z^{(i)} \\\\ \\qquad d w_2+=x_2^{(i)} d z^{(i)} \\\\ \\qquad d b+=d z^{(i)} \\\\$\n",
    "$ \\quad J /=m $  \n",
    "$ \\quad d w_1 /=m ; d w_2 /=m ; d b /=m$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting  \n",
    "\n",
    "### What is broadcasting in Python?  \n",
    "\n",
    "The examples and explanation which are listed below is enough for myself to understand and use this definition in this course. [Here are more details given by Numpy website](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n",
    "\n",
    "### Example\n",
    "\n",
    "<img src=\"images\\broadcasting example.png\" width=\"400\">\n",
    "\n",
    "The calculation we want is really to sum up each of the four columns of this matrix to get the total number of calories in 100 grams of apples, beef, eggs, and potatoes. And then to divide throughout the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56.    0.    4.4  68. ]\n",
      " [  1.2 104.   52.    8. ]\n",
      " [  1.8 135.   99.    0.9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A=np.array([[56.0,0.0,4.4,68.0],\n",
    "            [1.2,104.0,52.0,8.0],\n",
    "            [1.8,135.0,99.0,0.9]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59.  239.  155.4  76.9]\n"
     ]
    }
   ],
   "source": [
    "cal = A.sum(axis=0) #axis=0 means sum vertically\n",
    "print(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94.91525424  0.          2.83140283 88.42652796]\n",
      " [ 2.03389831 43.51464435 33.46203346 10.40312094]\n",
      " [ 3.05084746 56.48535565 63.70656371  1.17035111]]\n"
     ]
    }
   ],
   "source": [
    "percentage = 100*A/cal.reshape(1,4) #reshape(1,4) can be deleted\n",
    "print(percentage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 cases when python do broadcasting:  \n",
    "- matrix add a real number:  \n",
    "    \n",
    "  $\\left[\\begin{array}{l}1 \\\\ 2 \\\\ 3 \\\\ 4\\end{array}\\right]+100=\\left[\\begin{array}{l}1 \\\\ 2 \\\\ 3 \\\\ 4\\end{array}\\right]+\\left[\\begin{array}{l}100 \\\\ 100 \\\\ 100 \\\\ 100\\end{array}\\right]=\\left[\\begin{array}{l}101 \\\\ 102 \\\\ 103 \\\\ 104\\end{array}\\right]$\n",
    "- matrix add matrix:   \n",
    "    \n",
    "  $\\left[\\begin{array}{lll}1 & 2 & 3 \\\\ 4 & 5 & 6\\end{array}\\right]+\\left[\\begin{array}{lll}100 & 200 & 300\\end{array}\\right]=\\left[\\begin{array}{lll}1 & 2 & 3 \\\\ 4 & 5 & 6\\end{array}\\right]+\\left[\\begin{array}{lll}100 & 200 & 300 \\\\ 100 & 200 & 300\\end{array}\\right]=\\left[\\begin{array}{lll}101 & 202 & 303 \\\\ 104 & 205 & 306\\end{array}\\right]$  \n",
    "    \n",
    "    \n",
    "  $\\left[\\begin{array}{lll}1 & 2 & 3 \\\\ 4 & 5 & 6\\end{array}\\right]+\\left[\\begin{array}{l}100 \\\\ 200\\end{array}\\right]=\\left[\\begin{array}{lll}1 & 2 & 3 \\\\ 4 & 5 & 6\\end{array}\\right]+\\left[\\begin{array}{ccc}100 & 100 & 100 \\\\ 200 & 200 & 200\\end{array}\\right]=\\left[\\begin{array}{ccc}101 & 102 & 103 \\\\ 204 & 205 & 206\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82236043 -0.23316852  1.70631536  0.05589387 -0.07809429]\n",
      "(5,)\n",
      "[ 0.82236043 -0.23316852  1.70631536  0.05589387 -0.07809429]\n",
      "3.6513791981434345\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(5)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.T)\n",
    "print(np.dot(a,a.T)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we use this way to generate $a$, we can see that $a$ and $a^T$ are same and their product is a number. So, we'd better point out the shape of $a$ when generate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43003489]\n",
      " [-0.33991356]\n",
      " [-0.38556682]\n",
      " [-0.3753623 ]\n",
      " [ 0.30747038]]\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(5,1)\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43003489 -0.33991356 -0.38556682 -0.3753623   0.30747038]]\n"
     ]
    }
   ],
   "source": [
    "print(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18493    -0.14617469 -0.16580718 -0.16141889  0.13222299]\n",
      " [-0.14617469  0.11554123  0.13105939  0.12759074 -0.10451335]\n",
      " [-0.16580718  0.13105939  0.14866177  0.14472725 -0.11855038]\n",
      " [-0.16141889  0.12759074  0.14472725  0.14089686 -0.11541279]\n",
      " [ 0.13222299 -0.10451335 -0.11855038 -0.11541279  0.09453804]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(a,a.T)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(4,3)\n",
    "y = np.random.randn(1,3)\n",
    "c=x*y\n",
    "print(c.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x=np.array([[[1],[2]],[[3],[4]]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[[1],[2]],[[3],[4]]])\n",
    "print(x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
